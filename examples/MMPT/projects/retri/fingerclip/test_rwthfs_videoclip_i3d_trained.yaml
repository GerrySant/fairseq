dataset:
  max_video_len: 140
  max_len: 96
  split: test
  video_processor: RWTHFSRawVideoProcessor
  aligner: DSVideoAligner
  bert_name: bert-base-uncased
  meta_processor: RWTHFSMetaProcessor
  text_processor: TextProcessor
  test_path: data/rwthfs/test.txt
  val_path: data/rwthfs/val.txt
  train_path: data/rwthfs/train.txt
  gesture_id_path: data/rwthfs/gesture_ids.txt
  vfeat_dir: /home/gsantm/common/RWTH_Fingerspelling/npy_videos
slurm_config: big
task_type: local_predict
fairseq:
  common_eval:
    path: /home/gsantm/common/RWTH_Fingerspelling/fingerclip_experiments/rwthfs_i3d/checkpoint_best.pt
  dataset:
    num_workers: 2
    batch_size: 8
    valid_subset: test
model:
  model_cls: MMFusionWithI3D
  mm_encoder_cls: null
  video_encoder_cls: MMBertForEncoder
  text_encoder_cls: BertModel
  num_hidden_video_layers: 6
  vfeat_dim: 1024
  checkpoint_path: '/shares/iict-sp2.ebling.cl.uzh/zifjia/bsl1k/data/bsl5k.pth.tar'
  num_classes: 5383
  num_in_frames: 16
  path_to_i3d_repo: "/home/gsantm/repositories/bsl1k/"
eval:
  save_path: /home/gsantm/common/RWTH_Fingerspelling/fingerclip_experiments/rwthfs_i3d/eval
input_dim: 1024
metric: RWTHFSMetric
predictor: RetrievalPredictor