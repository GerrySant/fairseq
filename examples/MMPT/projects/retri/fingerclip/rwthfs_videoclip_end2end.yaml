dataset:
  max_video_len: 140
  max_len: 96
  video_processor: RWTHFSRawVideoProcessor
  bert_name: bert-base-uncased
  meta_processor: RWTHFSMetaProcessor
  text_processor: TextProcessor
  test_path: data/rwthfs/test.txt
  val_path: data/rwthfs/val.txt
  train_path: data/rwthfs/train.txt
  gesture_id_path: data/rwthfs/gesture_ids.txt
  vfeat_dir: /home/gsantm/common/RWTH_Fingerspelling/npy_videos
  aligner: DSVideoAligner
fairseq:
  common:
    fp16: true
    tensorboard_logdir: run
    log_interval: 1000
  dataset:
    num_workers: 2
    batch_size: 11
  optimization:
    lr:
    - 5.0e-05
    clip_norm: 2.0
    optimizer: adam
    adam_betas: (0.9, 0.98)
    lr_scheduler: polynomial_decay
    total_num_update: 1000000
    warmup_updates: 1000
    weight_decay: 0.0
    ddp_backend: no_c10d
    max_epoch: 25
  checkpoint:
    no_epoch_checkpoints: true
    reset_optimizer: true
    reset_dataloader: true
    reset_meters: true
    save_dir: /home/gsantm/common/RWTH_Fingerspelling/fingerclip_experiments/rwthfs_videoclip_end2end/
task_type: sweep_small
model:
  model_cls: MMFusionWithI3D
  mm_encoder_cls: null
  video_encoder_cls: MMBertForEncoder
  text_encoder_cls: BertModel
  num_hidden_video_layers: 6
  vfeat_dim: 1024
  checkpoint_path: '/shares/iict-sp2.ebling.cl.uzh/zifjia/bsl1k/data/bsl5k.pth.tar'
  num_classes: 5383
  num_in_frames: 16
  path_to_i3d_repo: "/home/gsantm/repositories/bsl1k/"
  i3d_batch_size: 16
loss:
  loss_cls: MMContraLoss
input_dim: 1024
